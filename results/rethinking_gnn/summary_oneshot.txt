The study aimed to enhance the expressive power of Graph Neural Networks (GNNs) by exploring graph biconnectivity, which includes properties like cut vertices and cut edges. The authors introduced a novel metric-based framework called Generalized Distance Weisfeiler-Lehman (GD-WL) to systematically and provably capture these properties. They demonstrated that most existing GNN architectures, including MPNNs and their advanced variants, fail to effectively handle biconnectivity problems. However, they showed that the Equivariant Subgraph Aggregation Network (ESAN) with the DSS-WL algorithm could distinguish cut vertices and cut edges. To address efficiency, the authors proposed GD-WL, incorporating both Shortest Path Distance (SPD) and Resistance Distance (RD), achieving expressiveness for all biconnectivity metrics with a lower computational cost than DSS-WL. They implemented this framework in a Transformer-like architecture called Graphormer-GD, proving its expressive power and efficiency. Empirical evaluations on synthetic tasks confirmed Graphormer-GD's ability to identify biconnectivity metrics perfectly, and real-world benchmarks demonstrated its superior performance over existing GNN models.