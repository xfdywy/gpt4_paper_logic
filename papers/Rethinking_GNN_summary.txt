The paper "Rethinking the Expressive Power of GNNs via Graph Biconnectivity" investigates the limitations and potentials of Graph Neural Networks (GNNs) by examining their ability to handle graph biconnectivity problems. Traditionally, the expressiveness of GNNs has been benchmarked against the Weisfeiler-Lehman (WL) test. However, this test has its limitations, prompting the authors to propose a new class of expressivity metrics based on graph biconnectivity. Biconnectivity includes key concepts like cut vertices, cut edges, and biconnected components, which can be efficiently calculated using linear-time algorithms.

The authors critically review existing GNN architectures and find that most of them, including the classic Message-Passing Neural Networks (MPNNs) and advanced models like Graph Substructure Networks (GSNs), fail to solve even basic biconnectivity problems. For instance, these models cannot reliably identify whether a graph contains cut vertices or edges, which are fundamental tasks related to biconnectivity. The Equivariant Subgraph Aggregation Network (ESAN) framework stands out as an exception, as it can theoretically identify cut vertices and edges. The paper provides a rigorous justification for ESAN's expressiveness, especially when using the DSS-WL algorithm with a node marking policy.

To address the limitations of existing models, the authors introduce the Generalized Distance Weisfeiler-Lehman (GD-WL) framework. This novel approach enhances the traditional WL test by incorporating distance metrics into the aggregation procedure, significantly improving its expressiveness for biconnectivity problems. The paper proves that the Shortest Path Distance WL (SPD-WL) is fully expressive for edge-biconnectivity issues, while the Resistance Distance WL (RD-WL) is fully expressive for vertex-biconnectivity problems. Furthermore, the combination of these two metrics within the GD-WL framework ensures full expressiveness for all biconnectivity metrics.

The GD-WL framework is also computationally efficient, requiring only linear space and quadratic time per iteration, making it suitable for large-scale tasks. Additionally, GD-WL can be implemented using a Transformer-like architecture, resulting in the Graphormer-GD model. This model injects distance information into Multi-head Attention mechanisms, retaining full parallelizability and expressiveness.

Empirical evaluations on synthetic and real-world datasets demonstrate the efficacy of Graphormer-GD. In synthetic tasks like cut vertex and cut edge detection, Graphormer-GD achieves 100% accuracy, outperforming baseline GNNs. In real-world tasks using the ZINC dataset, Graphormer-GD also surpasses existing models in terms of Mean Absolute Error (MAE), confirming its practical utility.

In conclusion, the paper provides a thorough theoretical and empirical investigation into the expressiveness of GNNs via graph biconnectivity. It highlights the limitations of existing models and introduces the GD-WL framework as a robust solution. The findings suggest that incorporating distance metrics into GNN architectures can significantly enhance their ability to handle complex graph-structured data, paving the way for more powerful and efficient GNN designs.
